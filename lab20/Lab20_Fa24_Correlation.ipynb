{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_27BjhJ06cw"
      },
      "source": [
        "# ATMS 305, Fall 2024 -- Lab20: Correlation\n",
        "# Today we'll start talking about statistics with: Correlation\n",
        "#\n",
        "# Info:\n",
        "#  scipy stats tutorial: https://docs.scipy.org/doc/scipy/tutorial/stats.html\n",
        "#  scipy lectures/stats: https://scipy-lectures.org/packages/statistics/index.html\n",
        "#  Pearson correlation coefficient: https://en.wikipedia.org/wiki/Pearson_correlation_coefficient\n",
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGLrlqZx1CA2"
      },
      "source": [
        "# >> A. IMPORT\n",
        "#\n",
        "#  1. import as usual: (a) numpy (b) matplotlib.pyplot (c) pandas\n",
        "#  2. add to this:\n",
        "#        import scipy as sp\n",
        "#        import plotly.express as px\n",
        "#        from scipy.signal import find_peaks\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# >> B. CORRELATION COEFFICIENT (Markdown figure)\n",
        "#\n",
        "#  We're going to generate some curves and compute their correlation -\n",
        "#    .. in particular, their *correlation coefficient*.\n",
        "#\n",
        "#  Wikipedia has a nice figure for this.\n",
        "#  a) Insert a text cell below this one. We'll use Markdown next.\n",
        "#  a) Show a heading \"CORRELATION\" first --\n",
        "#       ... help:  https://python-markdown.github.io/extensions/toc/\n",
        "#  b) After the above heading, display the image listed below\n",
        "#       ... help:  https://stackoverflow.com/questions/10628262/inserting-image-into-ipython-notebook-markdown\n",
        "#       ... >URL:  https://upload.wikimedia.org/wikipedia/commons/3/34/Correlation_coefficient.png"
      ],
      "metadata": {
        "id": "rVqP6XpumkrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# >> C. SINE CURVES\n",
        "#\n",
        "# Now you generate Two sine curves.\n",
        "# These curves have a phase angle (shift) of 180 degrees: Opposites.\n",
        "# This is the definition of \"negative correlation.\"\n",
        "#\n",
        "# PLOTS:\n",
        "#   1. After the y1= and y2= statements below, add plt.plot() code --\n",
        "#      a) plot y1 as solid blue and\n",
        "#      b) plot y2 as dashed red .. on the same plot figure!\n",
        "#\n",
        "#   2. Run the code.  Change nx to 20.  Run it again.\n",
        "#      Much better!  That's all for this cell.\n",
        "#\n",
        "#   3. p.s.: NX is the number of \"grid points\" defining the curves;\n",
        "#            angle is the phase shift angle (degrees) between y1, y2.\n",
        "nx = 7\n",
        "angle = 180.0\n",
        "x = np.linspace(0., 2.*np.pi, nx);\n",
        "y1 = 10 + 5*np.sin(x);\n",
        "y2 = 20 + 5*np.sin(x - np.pi/180.*angle);\n"
      ],
      "metadata": {
        "id": "cuoYyQUFEJ9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# >> D. CURVES + CORRELATION\n",
        "#\n",
        "# STATS:\n",
        "#   1. Let's use scipy.stat's \"pearsonr()\" routine to analyze the two\n",
        "#      curves y1,y2.  pearsonr() returns two values.  Code it like this:\n",
        "#\n",
        "#            r,p = sp.stats.pearsonr(y1,y2)\n",
        "#\n",
        "#      r, the correlation coefficient, is the >>strength<< of the correlation.\n",
        "#          r ranges from -1 to +1 like the figure you displayed earlier.\n",
        "#          r=1 is \"perfect\" correlation.\n",
        "#      p, or the 'p-value', is the >>probability<< we would find this result\n",
        "#          from uncorrelated datasets. If p < 0.05 (5%), we say\n",
        "#          the correlation \"r\" is **Statistically significant**\n",
        "#\n",
        "# PLOTS:\n",
        "#   2. Repeat your plt.plot() statements from the last cell - here.\n",
        "#      a) add label= statements to each plt.plot: \"y1\" and \"y2\"\n",
        "#      b) add the legend.\n",
        "#\n",
        "#   3. Add xlabel: Array index  ..and.. ylabel: y1,y2 value\n",
        "#   4. Add a title. Put the phase shift \"angle\", r, and p in the plot title.\n",
        "#      >Do it like this (w/LaTeX formatting for degrees symbol, $^\\circ$):\n",
        "#\n",
        "#        plt.title('%d$^\\circ$phase, corr %.2f, p=%.2f' % (angle,r,p) );\n",
        "#\n",
        "# PEAKS:\n",
        "#   5. Because we need it later, try scipy.signal's find_peaks() to show\n",
        "#      where the y1 max is located ... then draw a dotted line at the peak.\n",
        "#      As you will see, it is \"close\".  Add this code:\n",
        "#\n",
        "#           peaks,_ = find_peaks(y1);\n",
        "#           plt.axvline(peaks,linestyle=':');    # vert line at peaks\n",
        "#\n",
        "#      FYI, the \",_\" says to ignore other data returned by find_peaks().\n"
      ],
      "metadata": {
        "id": "6c5Oxt_Yqkmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# >> E. CORRELATION FOR A RANGE OF PHASE ANGLES\n",
        "#\n",
        "#  180 degrees was \"out of phase\" and gave a correlation of -1.\n",
        "#  Here we try phase angles of 0, 90, ..., 360 degrees.\n",
        "#\n",
        "#  1. Start a figure with size 6,9 (or choose your own)\n",
        "#  2. Start a for-loop whose loop variable \"n\" runs from 0-4 inclusive.\n",
        "#     Inclusive: don't leave off \"4\" !!\n",
        "#     This means you will make 5 plots in total.\n",
        "#  3. INSIDE the loop:\n",
        "#    a) plt.subplot(3,2,n+1)\n",
        "#    b) set \"angle\" equal to n*90\n",
        "#    c) use the same expression as previously:  y2 = ...\n",
        "#    d) plot y1 and y2 as before with legend.\n",
        "#    e) compute the pearson variables r,p as before.\n",
        "#    f) use the same title as before.\n",
        "#    g) don't worry about find_peaks() here.\n",
        "#  4. Outside of the loop, call tight_layout\n",
        "#\n",
        "# CHECK: you should have 5 plots, \"mostly\" filling up a 3-row 2-column figure.\n"
      ],
      "metadata": {
        "id": "HBQ-Cu1mEQdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-FwqnZ41ONd"
      },
      "source": [
        "# >> F. GET STORM SIMULATION DATA\n",
        "#\n",
        "# Now we'll shift to \"real\" data - well, a simulation of a supercell thunderstorm.\n",
        "# This data follows a mesocyclone (storm rotation center) as it\n",
        "#   intensifies and weakens, and the wind/rain/etc. near or above it.\n",
        "#\n",
        "# The first column is time, starting at 133 minutes.\n",
        "#\n",
        "#  1. Get this file:  rfd.atmos.uiuc.edu/305/supercell.txt\n",
        "#\n",
        "#  2. Use \"!head -5 filename\"      ...to see the first 5 lines of the file.\n",
        "#     > There are two comment lines, then the headings line and data following.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGtwQoFs1uCu"
      },
      "source": [
        "# >> G. READ STORM DATA\n",
        "#\n",
        "#  1. Read the data file with pandas' read_table() function into variable 'data'.\n",
        "#     Use option skiprows= to skip over 2 comment lines mentioned previously.\n",
        "#     You will also need this option: delim_whitespace=True\n",
        "#\n",
        "#  2. Finish with data.head(2) to make sure all is well.\n",
        "#\n",
        "#  3. FYI, we can refer to the 5th column with any of these:\n",
        "#        data.Rain\n",
        "#        data['Rain']\n",
        "#        data.iloc[:,4]      # all rows, python column=4\n",
        "#\n",
        "#  4. FYI #2, data.shape reveals 48 rows (times) and 20 columns (fields).\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRbwGRoh56SL"
      },
      "source": [
        "# >> H. QUICK SUMMARY\n",
        "#\n",
        "#  1. Use .describe() with your data array to get the min, max etc.\n",
        "#\n",
        "#  2. You should see min and max Time of 133 and 180, and maximum air\n",
        "#     rotation (vorticity) at the ground (VortSfc) of 8928.9, which\n",
        "#     is really 0.089 sec^-2. (stormy people: mesocyclone usually ~ 0.01/s^2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# >> I. FIND AND LABEL PEAKS (in VortSfc, the surface rotation)\n",
        "#\n",
        "#  1. Use the find_peaks() function to identify the maxima in VortSfc.\n",
        "#   a) call find_peaks as done before, but for array: data.VortSfc\n",
        "#   b) results from find_peaks should be stored in \"peaks\" as before\n",
        "#   b) add these options when calling find_peaks() to isolate the maxima:\n",
        "#          distance=10\n",
        "#          height=3000\n",
        "#   c) we'll use the peak data in a moment.\n",
        "#\n",
        "#  2. plt.plot() field data.VortSfc versus data.Time\n",
        "#    a) add xlabel: Time (min)\n",
        "#    b) add ylabel: VortSfc x10^-5/s^2\n",
        "#    c) add  title: Surface vorticity vs. time\n",
        "#    d) use any color, or let plt.plot() pick for you\n",
        "#\n",
        "#  3. Plot an asterisk at each peak with:\n",
        "#        plt.plot(data.Time[peaks],data.VortSfc[peaks],'*');\n",
        "#\n",
        "#  4. Draw a vertical dotted line at each peak with:\n",
        "#       for xc in peaks:\n",
        "#         plt.axvline(x=data.Time[xc],linestyle=':',color='tan');\n"
      ],
      "metadata": {
        "id": "VVPZcZflCGvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37ZAicWl-VNk"
      },
      "source": [
        "# >> J. 3-PANEL PLOT\n",
        "#\n",
        "#  1. Do find_peaks again on data.VortSfc but use option: height=6000\n",
        "#  2. Start a 12x6\" figure, with a 1-row, 3-column plot.\n",
        "#  3. On all 3 plots, use data.Time as the x-axis variable when plotting.\n",
        "#  4. On all 3 plots, use xlabel: Time (min)\n",
        "#\n",
        "#  5. On left, plot Vortsfc (red) vs. time,\n",
        "#              ylabel: VortSfc (x10^-5/sec),\n",
        "#              title: Surface vertical vorticity\n",
        "#  6. In middle, plot P (blue) vs. time,\n",
        "#              ylabel: Pres (mb),\n",
        "#              title: Surface perturbation pressure\n",
        "#  7. On right, plot Wlow (green) vs. time,\n",
        "#              ylabel: Wlow (m/s),\n",
        "#              title: Low-level vertical motion\n",
        "#\n",
        "#  8. Now add code to plot vertical dotted lines at peak locations\n",
        "#     for all 3 plot panels.  So after each subplot, x/ylabel\n",
        "#     and title, you will repeat the \"for xc in peaks...\" code\n",
        "#     used in the last cell.  You pick the line color.\n",
        "#\n",
        "#  9. Finish with tight_layout\n",
        "#\n",
        "# CHECK: when the storm's rotation intensifies (red curve), the\n",
        "#   pressure falls, and a downdraft is produced soon after.\n",
        "#   When we check, VortSfc and Pres will have negative correlation!\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7e7J6ViBBQz"
      },
      "source": [
        "# >> K. OVERLAY 2-AXIS PLOT (of VortSfc and Pres vs. Time)\n",
        "#\n",
        "# ... using Pandas plotting.\n",
        "#\n",
        "#  1. ax = data.plot(x=\"Time\",y=\"VortSfc\", option, option...\n",
        "#        ... with options:\n",
        "#              color='r'          ... for solid red VortSfc\n",
        "#              figsize=(10,6)     ... set figsize inside the .plot()\n",
        "#\n",
        "#  2. data.plot(x=\"Time\",y=\"P\", option, option...\n",
        "#        ... with options:\n",
        "#              color='b'          ... for blue\n",
        "#              style='--'         ... for Dashed blue\n",
        "#              legend=True        ... to add a legend\n",
        "#              secondary_y=True   ... to use the right-Y axis for plot\n",
        "#              ax=ax              ... to overlay on the prior ax=data.plot()\n",
        "#\n",
        "#  3. add Left Y-axis label with ax.set_ylabel() to say: VortSfc\n",
        "#  4. add Right Y-axis label with, no kidding: ax.right_ax.set_ylabel('Pres');\n",
        "#\n",
        "#  5. grab pearson correlation coefficient code from before; use it here\n",
        "#     to get r,p = sp.stats etc etc. for data.VortSfc and data.P\n",
        "#\n",
        "#  6. add a title that includes the r,p values, each with 2 digits after the\n",
        "#     decimal point, so title looks like:\n",
        "#\n",
        "#          Surface vorticity and pressure vs. time, corr=X.XX, p=Y.YY'\n",
        "#\n",
        "#     with values of r and p in place of X.XX and Y.YY shown here.\n",
        "#     ... this all goes into: ax.set_title()\n",
        "#\n",
        "# CHECK: you should get one solid red line (VortSfc), one dashed blue line (P),\n",
        "#     a legend in the plot box, a title above the plot box, and your title should\n",
        "#     show the correlation value which is approximately -0.9\n",
        "#     (negatively correlated)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7a6ssrvw_Maa"
      },
      "source": [
        "# >> L. SCATTER PLOT\n",
        "#\n",
        "#  The previous cell make clear that VortSfc and Pres increase/decrease in opposite ways,\n",
        "#  hence the negative correlation.  Let's make a scatter plot showing how this happens.\n",
        "#\n",
        "#  1. plotly.express is already imported as 'px' at top of this notebook.\n",
        "#     do you remember how to make a scatter plot with px.scatter()?\n",
        "#     check your earthquake program ...\n",
        "#\n",
        "#  2. Make a px.scatter plot ... using fig=px.scatter( data_set, x=....)\n",
        "#       data set is: data\n",
        "#       x='VortSfc'\n",
        "#       y='P'\n",
        "#       color is data.Wlow\n",
        "#       size is data.Rain\n",
        "#\n",
        "#  3. Add title with fig.update_layout(title_text=' ')\n",
        "#       with title: Scatter plot of VortSfc vs. P\n",
        "#\n",
        "#  4. Your x- and y-labels are done for you when you used x='VortSfc' etc.\n",
        "#  5. The colorbar is done for you also ... darker is stronger negative Wlow\n",
        "#  6. Remember you can mouse-over the circles to see the data.\n",
        "#\n",
        "# CHECK: higher VortSfc is found only with lower (negative) values of P,\n",
        "#   and strongly negative Wlow only happens with high VortSfc, low P\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8vwTa9p-3EC"
      },
      "source": [
        "# >> M. CORRELATIONS\n",
        "#\n",
        "# Suppose we want to compare each data column to every other column and compute\n",
        "# the correlation for each pair ... we can do this in one statement!\n",
        "#\n",
        "#  1. corr=data.corr(method='pearson')        # does everything for us!\n",
        "#  2. corr                                    # shows contents of 'corr'\n",
        "#\n",
        "# CHECK: every field correlated against itself has correlation = 1.00, so there is\n",
        "# a diagonal set of 1.000 values in the table.  Qgr is all zeros, and here: NaN\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBK4r_0kDIlh"
      },
      "source": [
        "# >> N. HEATMAP\n",
        "#\n",
        "#  Let's see all those correlations in a heatmap colored-table of array 'corr'\n",
        "#\n",
        "#  1. Import seaborn as sb\n",
        "#  2. Make a large-r figure; I used plt.figure() for a 14x8\" figure\n",
        "#  3. Try: sb.heatmap(corr, annot=True)\n",
        "#\n",
        "#  4. It isn't so easy to see what we want here.  Add this option\n",
        "#     to the sb.heatmap call:  cmap='RdBu_r'\n",
        "#     ... now the bold colors are for strong (+/-) correlations.\n",
        "#     Find similar color maps by searching: matplotlib diverging maps\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNl42Z6GDebI"
      },
      "source": [
        "# >> O. PLOT \"IMPORTANT\" FIELDS\n",
        "#\n",
        "# Suppose you had 1000's of fields.  You only want to see those with strong\n",
        "# correlations to VortSfc.  We'll step through all fields and only plot\n",
        "# those with correlation < -0.5 =or= > +0.5 .\n",
        "#\n",
        "#  1. Loop variable 'col' from 1 to the number of columns (2nd dimension of data)\n",
        "#       (so, range() goes to columns-1 as usual)\n",
        "#\n",
        "#  2. Inside the loop:\n",
        "#   a) print the column number (2-digit format), and the\n",
        "#      name of the column (print with format %s, and use data.columns[col]\n",
        "#\n",
        "#   b) set 'array' to the data array for this column.  You can do that using\n",
        "#      data.iloc[:,col], storing all rows and just this column to 'array'\n",
        "#\n",
        "#   c) set variable 'name' to the name of this column, which you can\n",
        "#      get using data.columns[col]\n",
        "#\n",
        "#   d) we are going to omit two columns from our search: VortSfc (not need\n",
        "#      to correlate VortSfc with itself), and also Qgr (which is all zeros).\n",
        "#      Do this by an if statement, making sure name does not equal 'VortSfc'\n",
        "#      and name does not equal 'Qgr'.  What follows are for all those fields\n",
        "#      without those names:\n",
        "#\n",
        "#   e) Inside the if ... :  ... statement:\n",
        "#\n",
        "#      (1) compute the correlation r and p-value between data.VortSfc, and array\n",
        "#      (2) if r is less than -0.5 or r is greater than +0.5:\n",
        "#\n",
        "#        *) Print: VortSfc correlated with column (insert 2-digit col),\n",
        "#             name (insert name, %s), r=(insert value of r, formatted ##.##)\n",
        "#        *) Repeat the cell H code for a plot of VortSfc vs. time, overlaid\n",
        "#             with a plot of 'array' vs. time formatted as we did P in cell H.\n",
        "#        *) Format the title as we did in cell H, inserting the column name, r and p.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# USE THIS cell to SAVE NOTEBOOK as HTML\n",
        "# %%shell\n",
        "# jupyter nbconvert --to html  NAME"
      ],
      "metadata": {
        "id": "ziaP7BTkts-6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}